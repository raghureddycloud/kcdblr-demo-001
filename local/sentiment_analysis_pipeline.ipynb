{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72631e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages (needs to be run every time in new environments)\n",
    "!pip install pandas scikit-learn matplotlib seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "\n",
    "# Global variables (state management issue)\n",
    "DATA_DIR = \"pipeline_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa39798",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "if os.path.exists(DATA_DIR):\n",
    "    shutil.rmtree(DATA_DIR)  # Dangerous - could delete important data!\n",
    "    \n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(f\"üìÅ Created directory: {DATA_DIR}\")\n",
    "\n",
    "# Manual cleanup function (often forgotten)\n",
    "def cleanup_temp_files():\n",
    "    \"\"\"Manual cleanup - often forgotten or incomplete\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(DATA_DIR):\n",
    "            shutil.rmtree(DATA_DIR)\n",
    "        print(\"üßπ Temp files cleaned\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Cleanup failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c74af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Data Preparation - typically hardcoded or inconsistent\n",
    "def prepare_data():\n",
    "    \"\"\"Manual data preparation - no versioning or lineage tracking\"\"\"\n",
    "    print(\"=== Step 1: Data Preparation ===\")\n",
    "    \n",
    "    # Hardcoded sample data (not parameterized)\n",
    "    data = {\n",
    "        'review': [\n",
    "            'This product is amazing!',\n",
    "            'Terrible quality, waste of money',\n",
    "            'Good value for money', \n",
    "            'Poor customer service',\n",
    "            'Excellent product, highly recommend',\n",
    "            'Not worth the price',\n",
    "            'Great experience overall',\n",
    "            'Disappointed with purchase',\n",
    "            'Outstanding quality and service',\n",
    "            'Worst purchase ever made',\n",
    "            'Decent product for the price',\n",
    "            'Highly satisfied with quality'\n",
    "        ],\n",
    "        'sentiment': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Manual file saving (no metadata tracking)\n",
    "    output_path = os.path.join(DATA_DIR, 'raw_data.pkl')\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(df, f)\n",
    "    \n",
    "    print(f\"üìä Processed {len(df)} reviews\")\n",
    "    print(\"Sample data:\")\n",
    "    display(df.head(3))\n",
    "    \n",
    "    return df, output_path\n",
    "\n",
    "# Execute (must remember to run cells in order!)\n",
    "df_raw, raw_data_path = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1684d1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Engineering - tightly coupled to previous cell\n",
    "def extract_features(input_path):\n",
    "    \"\"\"Feature extraction - manual parameter tuning\"\"\"\n",
    "    print(\"\\n=== Step 2: Feature Engineering ===\")\n",
    "    \n",
    "    try:\n",
    "        # Manual file loading (no error handling for missing files)\n",
    "        with open(input_path, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Error: Run the data preparation cell first!\")\n",
    "        return None\n",
    "    \n",
    "    # Hardcoded hyperparameters (not configurable)\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=100,  # Fixed value\n",
    "        stop_words='english',  # Not parameterized\n",
    "        ngram_range=(1, 1)  # Not tunable\n",
    "    )\n",
    "    \n",
    "    X = vectorizer.fit_transform(df['review'])\n",
    "    y = df['sentiment'].values\n",
    "    \n",
    "    # Manual file management\n",
    "    X_path = os.path.join(DATA_DIR, 'features_X.pkl')\n",
    "    y_path = os.path.join(DATA_DIR, 'features_y.pkl') \n",
    "    vectorizer_path = os.path.join(DATA_DIR, 'vectorizer.pkl')\n",
    "    \n",
    "    # Multiple pickle operations (inefficient)\n",
    "    with open(X_path, 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "    with open(y_path, 'wb') as f:\n",
    "        pickle.dump(y, f)\n",
    "    with open(vectorizer_path, 'wb') as f:\n",
    "        pickle.dump(vectorizer, f)\n",
    "    \n",
    "    print(f\"üîß Feature matrix shape: {X.shape}\")\n",
    "    print(f\"üìù Vocabulary size: {len(vectorizer.get_feature_names_out())}\")\n",
    "    \n",
    "    return X, y, vectorizer, X_path, y_path, vectorizer_path\n",
    "\n",
    "# Execute (order dependency!)\n",
    "try:\n",
    "    X, y, vectorizer, X_path, y_path, vectorizer_path = extract_features(raw_data_path)\n",
    "except NameError:\n",
    "    print(\"‚ùå Error: raw_data_path not defined. Run previous cells first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794065b4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Model Training - no resource limits or monitoring\n",
    "def train_model(X_path, y_path):\n",
    "    \"\"\"Train model - manual hyperparameter management\"\"\"\n",
    "    print(\"\\n=== Step 3: Model Training ===\")\n",
    "    \n",
    "    # Manual loading (could fail silently)\n",
    "    try:\n",
    "        with open(X_path, 'rb') as f:\n",
    "            X = pickle.load(f)\n",
    "        with open(y_path, 'rb') as f:\n",
    "            y = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Loading failed: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Fixed train/test split (not configurable)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.3,  # Hardcoded\n",
    "        random_state=42,  # Fixed seed\n",
    "        stratify=y  # Not always appropriate\n",
    "    )\n",
    "    \n",
    "    # Model with fixed hyperparameters\n",
    "    model = LogisticRegression(\n",
    "        random_state=42,  # Fixed\n",
    "        max_iter=100,  # Could be insufficient\n",
    "        solver='lbfgs'  # Not optimized\n",
    "    )\n",
    "    \n",
    "    # Training without monitoring or early stopping\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Manual artifact saving\n",
    "    model_path = os.path.join(DATA_DIR, 'model.pkl')\n",
    "    test_X_path = os.path.join(DATA_DIR, 'X_test.pkl')\n",
    "    test_y_path = os.path.join(DATA_DIR, 'y_test.pkl')\n",
    "    \n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    with open(test_X_path, 'wb') as f:\n",
    "        pickle.dump(X_test, f)\n",
    "    with open(test_y_path, 'wb') as f:\n",
    "        pickle.dump(y_test, f)\n",
    "    \n",
    "    print(f\"ü§ñ Model trained successfully\")\n",
    "    print(f\"üìä Training samples: {len(X_train)}\")\n",
    "    print(f\"üß™ Test samples: {len(X_test)}\")\n",
    "    \n",
    "    return model, X_test, y_test, model_path, test_X_path, test_y_path\n",
    "\n",
    "# Execute (hoping previous cells worked!)\n",
    "try:\n",
    "    model, X_test, y_test, model_path, test_X_path, test_y_path = train_model(X_path, y_path)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training failed: {e}\")\n",
    "    print(\"Make sure all previous cells ran successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f14e08",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Model Evaluation - manual metric calculation\n",
    "def evaluate_model(model_path, test_X_path, test_y_path):\n",
    "    \"\"\"Evaluate model - limited metrics and reporting\"\"\"\n",
    "    print(\"\\n=== Step 4: Model Evaluation ===\")\n",
    "    \n",
    "    # Manual loading again\n",
    "    try:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        with open(test_X_path, 'rb') as f:\n",
    "            X_test = pickle.load(f)\n",
    "        with open(test_y_path, 'rb') as f:\n",
    "            y_test = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load artifacts: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Basic predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # Simple metrics (not comprehensive)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"üìà Accuracy: {accuracy:.3f}\")\n",
    "    print(\"\\nüìã Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))\n",
    "    \n",
    "    # Manual results saving (inconsistent format)\n",
    "    results = {\n",
    "        'accuracy': float(accuracy),\n",
    "        'predictions': y_pred.tolist(),\n",
    "        'actuals': y_test.tolist(),\n",
    "        'timestamp': pd.Timestamp.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    results_path = os.path.join(DATA_DIR, 'results.json')\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    return results, y_pred, y_proba\n",
    "\n",
    "# Execute evaluation\n",
    "try:\n",
    "    results, y_pred, y_proba = evaluate_model(model_path, test_X_path, test_y_path)\n",
    "    print(f\"\\nüíæ Results saved to: {os.path.join(DATA_DIR, 'results.json')}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Evaluation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d8e92f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Visualization - manual plotting with potential display issues\n",
    "def create_visualizations():\n",
    "    \"\"\"Create basic visualizations - limited interactivity\"\"\"\n",
    "    print(\"\\n=== Step 5: Visualization ===\")\n",
    "    \n",
    "    # Setup plots (might not display properly in all environments)\n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle('Model Performance Analysis', fontsize=16)\n",
    "    \n",
    "    try:\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['Negative', 'Positive'], \n",
    "                   yticklabels=['Negative', 'Positive'],\n",
    "                   ax=axes[0,0])\n",
    "        axes[0,0].set_title('Confusion Matrix')\n",
    "        axes[0,0].set_ylabel('True Label')\n",
    "        axes[0,0].set_xlabel('Predicted Label')\n",
    "        \n",
    "        # Probability Distribution\n",
    "        positive_probs = y_proba[:, 1]\n",
    "        axes[0,1].hist(positive_probs, bins=min(10, len(positive_probs)), \n",
    "                      alpha=0.7, edgecolor='black', color='skyblue')\n",
    "        axes[0,1].set_title('Positive Class Probabilities')\n",
    "        axes[0,1].set_xlabel('Probability')\n",
    "        axes[0,1].set_ylabel('Count')\n",
    "        \n",
    "        # Feature Importance (top features only)\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        coefficients = model.coef_[0]\n",
    "        \n",
    "        # Get top 10 features by absolute coefficient value\n",
    "        feature_importance = list(zip(abs(coefficients), coefficients, feature_names))\n",
    "        feature_importance.sort(reverse=True)\n",
    "        top_features = feature_importance[:10]\n",
    "        \n",
    "        features = [item[2] for item in top_features]\n",
    "        coefs = [item[1] for item in top_features]\n",
    "        colors = ['red' if c < 0 else 'green' for c in coefs]\n",
    "        \n",
    "        y_pos = range(len(features))\n",
    "        axes[1,0].barh(y_pos, coefs, color=colors, alpha=0.7)\n",
    "        axes[1,0].set_yticks(y_pos)\n",
    "        axes[1,0].set_yticklabels(features, fontsize=8)\n",
    "        axes[1,0].set_title('Top 10 Feature Weights')\n",
    "        axes[1,0].set_xlabel('Coefficient Value')\n",
    "        \n",
    "        # Simple accuracy bar\n",
    "        axes[1,1].bar(['Accuracy'], [results['accuracy']], color='lightgreen', alpha=0.7)\n",
    "        axes[1,1].set_ylim(0, 1)\n",
    "        axes[1,1].set_title('Model Accuracy')\n",
    "        axes[1,1].set_ylabel('Score')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Save plot manually (format hardcoded)\n",
    "        plot_path = os.path.join(DATA_DIR, 'performance_plots.png')\n",
    "        fig.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"üìä Plots saved to: {plot_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Visualization failed: {e}\")\n",
    "\n",
    "# Execute visualization\n",
    "try:\n",
    "    create_visualizations()\n",
    "except NameError as e:\n",
    "    print(f\"‚ùå Missing variables: {e}\")\n",
    "    print(\"Run all previous cells in order!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f1336",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Manual testing - no systematic validation\n",
    "def test_new_samples():\n",
    "    \"\"\"Test with new data - manual and error-prone\"\"\"\n",
    "    print(\"\\n=== Step 6: Manual Testing ===\")\n",
    "    \n",
    "    # Hardcoded test samples\n",
    "    test_reviews = [\n",
    "        \"This is absolutely fantastic!\",\n",
    "        \"Complete garbage, avoid at all costs\",\n",
    "        \"It's okay, nothing special\",\n",
    "        \"Exceeded my expectations completely!\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # Manual prediction process\n",
    "        X_new = vectorizer.transform(test_reviews)\n",
    "        predictions = model.predict(X_new)\n",
    "        probabilities = model.predict_proba(X_new)\n",
    "        \n",
    "        print(\"üîç Manual Test Results:\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for i, review in enumerate(test_reviews):\n",
    "            sentiment = \"üòä Positive\" if predictions[i] == 1 else \"üòû Negative\"\n",
    "            confidence = max(probabilities[i]) * 100\n",
    "            \n",
    "            print(f\"Review: '{review[:50]}{'...' if len(review) > 50 else ''}'\")\n",
    "            print(f\"Prediction: {sentiment} (Confidence: {confidence:.1f}%)\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Testing failed: {e}\")\n",
    "        print(\"Ensure all previous cells have been executed!\")\n",
    "\n",
    "# Execute testing\n",
    "test_new_samples()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cae83e5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def list_artifacts():\n",
    "    \"\"\"Manual artifact inspection - no metadata tracking\"\"\"\n",
    "    print(\"\\n=== Step 7: Artifact Management ===\")\n",
    "    \n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        print(\"‚ùå No artifacts directory found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìÇ Artifacts in '{DATA_DIR}':\")\n",
    "    total_size = 0\n",
    "    \n",
    "    for file in os.listdir(DATA_DIR):\n",
    "        file_path = os.path.join(DATA_DIR, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            size = os.path.getsize(file_path)\n",
    "            total_size += size\n",
    "            modified = os.path.getmtime(file_path)\n",
    "            mod_time = pd.Timestamp.fromtimestamp(modified).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            \n",
    "            print(f\"  üìÑ {file}\")\n",
    "            print(f\"     Size: {size:,} bytes\")\n",
    "            print(f\"     Modified: {mod_time}\")\n",
    "            print()\n",
    "    \n",
    "    print(f\"üíæ Total size: {total_size:,} bytes\")\n",
    "    \n",
    "    # Manual validation (often skipped)\n",
    "    required_files = ['raw_data.pkl', 'model.pkl', 'vectorizer.pkl', 'results.json']\n",
    "    missing_files = [f for f in required_files if f not in os.listdir(DATA_DIR)]\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"‚ö†Ô∏è  Missing files: {missing_files}\")\n",
    "    else:\n",
    "        print(\"‚úÖ All required artifacts present\")\n",
    "\n",
    "list_artifacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72072011",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Pipeline completion summary - manual tracking\n",
    "def pipeline_summary():\n",
    "    \"\"\"Show what we accomplished and the problems we faced\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéØ PIPELINE EXECUTION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    steps = [\n",
    "        \"‚úÖ Data Preparation\",\n",
    "        \"‚úÖ Feature Engineering\", \n",
    "        \"‚úÖ Model Training\",\n",
    "        \"‚úÖ Model Evaluation\",\n",
    "        \"‚úÖ Visualization\",\n",
    "        \"‚úÖ Manual Testing\",\n",
    "        \"‚úÖ Artifact Management\"\n",
    "    ]\n",
    "    \n",
    "    for step in steps:\n",
    "        print(step)\n",
    "    \n",
    "    try:\n",
    "        final_accuracy = results['accuracy']\n",
    "        print(f\"\\nüéØ Final Model Accuracy: {final_accuracy:.3f}\")\n",
    "    except:\n",
    "        print(\"\\n‚ùå Could not retrieve final accuracy\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üö® PROBLEMS WITH THIS APPROACH:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    problems = [\n",
    "        \"‚ùå Manual cell execution order dependency\",\n",
    "        \"‚ùå No automatic error handling or rollback\", \n",
    "        \"‚ùå Hard to reproduce across different environments\",\n",
    "        \"‚ùå No parameter management or experimentation tracking\",\n",
    "        \"‚ùå Manual file and state management\",\n",
    "        \"‚ùå No scalability or parallel execution\",\n",
    "        \"‚ùå No automated testing or validation\",\n",
    "        \"‚ùå Difficult to deploy to production\",\n",
    "        \"‚ùå No monitoring or logging infrastructure\",\n",
    "        \"‚ùå Version control challenges with notebooks\",\n",
    "        \"‚ùå No resource management or optimization\",\n",
    "        \"‚ùå Manual cleanup and artifact management\"\n",
    "    ]\n",
    "    \n",
    "    for problem in problems:\n",
    "        print(problem)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üí° KUBEFLOW ADVANTAGES:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    advantages = [\n",
    "        \"‚úÖ Automatic orchestration and dependency management\",\n",
    "        \"‚úÖ Containerized, reproducible environments\",\n",
    "        \"‚úÖ Automatic resource management and scaling\", \n",
    "        \"‚úÖ Built-in experiment tracking and versioning\",\n",
    "        \"‚úÖ Easy deployment and serving capabilities\",\n",
    "        \"‚úÖ Automated monitoring and logging\",\n",
    "        \"‚úÖ Parameter management and hyperparameter tuning\",\n",
    "        \"‚úÖ Parallel execution and optimization\",\n",
    "        \"‚úÖ Production-ready infrastructure\",\n",
    "        \"‚úÖ Team collaboration and sharing\",\n",
    "        \"‚úÖ Automated testing and validation frameworks\"\n",
    "    ]\n",
    "    \n",
    "    for advantage in advantages:\n",
    "        print(advantage)\n",
    "    \n",
    "    print(\"\\nüöÄ Ready to move to Kubeflow? Your pipeline will be:\")\n",
    "    print(\"   ‚Ä¢ More reliable and reproducible\")\n",
    "    print(\"   ‚Ä¢ Easier to scale and deploy\") \n",
    "    print(\"   ‚Ä¢ Better for team collaboration\")\n",
    "    print(\"   ‚Ä¢ Production-ready from day one\")\n",
    "\n",
    "pipeline_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be52c944",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Manual cleanup - often forgotten or incomplete\n",
    "print(\"üßπ MANUAL CLEANUP\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Optional cleanup (user might skip this)\n",
    "cleanup_choice = input(\"Delete temporary files? (y/N): \").lower().strip()\n",
    "\n",
    "if cleanup_choice == 'y':\n",
    "    try:\n",
    "        cleanup_temp_files()\n",
    "        print(\"‚úÖ Cleanup completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Cleanup failed: {e}\")\n",
    "        print(\"You may need to manually delete the files later\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Temporary files kept - remember to clean up later!\")\n",
    "    print(f\"   Directory: {DATA_DIR}\")\n",
    "    print(\"   This can accumulate and use disk space over time\")\n",
    "\n",
    "print(\"\\nüí≠ In Kubeflow: Automatic cleanup and resource management!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c012162",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## üìù Notebook Execution Notes:\n",
    "\n",
    "### Common Issues When Running This Notebook:\n",
    "1. **Cell Execution Order**: Must run cells in exact sequence\n",
    "2. **Variable Dependencies**: Later cells fail if earlier ones haven't run\n",
    "3. **Environment Issues**: Package installations may differ across systems\n",
    "4. **File Path Problems**: Manual path management leads to errors\n",
    "5. **Memory Management**: No automatic cleanup of large objects\n",
    "6. **State Confusion**: Easy to lose track of what's been executed\n",
    "\n",
    "### Why Kubeflow is Better:\n",
    "- **Automatic Orchestration**: No manual cell execution order\n",
    "- **Reproducible Environments**: Containerized components\n",
    "- **Parameter Management**: Easy configuration without code changes\n",
    "- **Scalability**: Automatic resource allocation and parallel execution\n",
    "- **Production Ready**: Built-in monitoring, logging, and deployment\n",
    "- **Team Collaboration**: Shareable, version-controlled pipelines"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
